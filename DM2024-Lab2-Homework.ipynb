{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name:楊哲銘\n",
    "\n",
    "Student ID: 113753219\n",
    "\n",
    "GitHub ID: jhemingy\n",
    "\n",
    "Kaggle name: Jhe Ming Yang\n",
    "\n",
    "Kaggle private scoreboard snapshot: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home exercises** in the [DM2024-Lab2-master Repo](https://github.com/didiersalazar/DM2024-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework) regarding Emotion Recognition on Twitter by this link: https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)**. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developing the model for the competition (You can use code and comment on it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Begin Assignment Here\n",
    "\n",
    "###Part 1 prepare data###\n",
    "#First, I merged all the data into a single DataFrame called emotionmerged_df, which was then split into test and train DataFrames.\n",
    "\n",
    "# Read data\n",
    "data = []\n",
    "with open('/kaggle/input/dm-2024-isa-5810-lab-2-homework/tweets_DM.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    " f.close()\n",
    "\n",
    "emotion = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/emotion.csv')\n",
    "\n",
    "data_identification = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/data_identification.csv')\n",
    "\n",
    "tweet_df = pd.DataFrame([\n",
    "    {\n",
    "        'tweet_id': item['_source']['tweet']['tweet_id'],\n",
    "        'text': item['_source']['tweet']['text'],\n",
    "        'hashtags': item['_source']['tweet']['hashtags'],\n",
    "        'crawldate': item['_crawldate']\n",
    "    }\n",
    "    for item in data\n",
    "])\n",
    "\n",
    "emotionmerged_df = pd.merge(tweet_df, emotion, on='tweet_id', how='inner')\n",
    "emotionmerged_df=pd.merge(data_identification,emotionmerged_df,  on='tweet_id', how='left')\n",
    "\n",
    "emotionmerged_df_test=emotionmerged_df[emotionmerged_df['identification']=='test']\n",
    "emotionmerged_df_train=emotionmerged_df[emotionmerged_df['identification']=='train']\n",
    "\n",
    "\n",
    "\n",
    "###Part 2: Use llm model to get embeddings###\n",
    "#The distilgpt2 model was used to generate embeddings for the training set\n",
    "\n",
    "#load llm model\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "model_name = \"distilgpt2\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).cuda()\n",
    "from torch.nn import DataParallel\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model = DataParallel(model)\n",
    "\n",
    "model =model.eval()\n",
    "\n",
    "#get embeddings and save as partquet file\n",
    "from tqdm import tqdm\n",
    "def get_batch_embeddings(texts, batch_size=128):\n",
    "    total = len(texts)\n",
    "    percent_step = total // 100 if total >= 100 else 1  # 每 1% 的步长\n",
    "    embeddings = []\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    with tqdm(total=100, desc=\"Generating Embeddings (1% steps)\") as pbar:\n",
    "        for i in range(0, total, batch_size):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048).to(\"cuda\")\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs, output_hidden_states=True)\n",
    "            batch_embeddings = outputs.hidden_states[-1].mean(dim=1)\n",
    "            embeddings.append(batch_embeddings.cpu().numpy())\n",
    "            if (i + batch_size) // percent_step > i // percent_step:\n",
    "                pbar.update((i + batch_size) // percent_step - i // percent_step)\n",
    "\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "train_texts = emotionmerged_df_train['text'].tolist()  # Extract texts\n",
    "train_embeddings = get_batch_embeddings(train_texts)\n",
    "\n",
    "# Combine embeddings with tweet IDs\n",
    "train_tweet_ids = emotionmerged_df_train['tweet_id'].tolist()\n",
    "embeddings_df = pd.DataFrame(train_embeddings)\n",
    "embeddings_df.insert(0, 'tweet_id', train_tweet_ids)  # Add tweet_id as the first column\n",
    "\n",
    "# Save the dataframe as a Parquet file\n",
    "parquet_file_path = 'train_embeddings.parquet'\n",
    "embeddings_df.to_parquet(parquet_file_path, engine='pyarrow', index=False)\n",
    "\n",
    "\n",
    "\n",
    "###Part 3: Use faiss to search the top k simular embedding vectors ###\n",
    "#After have all the embeddings, I upload the file as a kaggle dataset, then i store them to the faiss\n",
    "import faiss\n",
    "embedding_df = pd.read_parquet('/kaggle/input/embedding/embedding.parquet')\n",
    "embedding_df.head()\n",
    "embedding_df = pd.merge(embedding_df, emotion, on='tweet_id', how='inner')\n",
    "\n",
    "embeddings = np.array(embedding_df['embedding'].tolist())\n",
    "tweet_ids = embedding_df['tweet_id'].tolist()  \n",
    "emotions = embedding_df['emotion'].tolist() \n",
    "print(f\"Embedding shape: {embeddings.shape}\")\n",
    "\n",
    "embedding_dim = embeddings.shape[1] \n",
    "index = faiss.IndexFlatL2(embedding_dim)  \n",
    "faiss.normalize_L2(embeddings)  \n",
    "index.add(embeddings)  \n",
    "\n",
    "\n",
    "#Then for all test data's text, I translate it to embedding vectors\n",
    "#Use faiss to search the top 7 simular vectors and their emotions\n",
    "\n",
    "def search_faiss(query_vectors, top_k=7):\n",
    "\n",
    "    faiss.normalize_L2(query_vectors)\n",
    "    distances, indices = index.search(query_vectors, top_k)\n",
    "    results = []\n",
    "    for query_idx, neighbors in enumerate(indices):\n",
    "        result = {\n",
    "            \"query_idx\": query_idx,\n",
    "            \"neighbors\": [\n",
    "                {\n",
    "                    \"index\": neighbor_idx,\n",
    "                    \"tweet_id\": tweet_ids[neighbor_idx],  # 返回对应的 tweet_id\n",
    "                    \"emotions\": emotions[neighbor_idx],  # 返回情绪\n",
    "                    \"distance\": distances[query_idx][neighbor_rank],\n",
    "                }\n",
    "                for neighbor_rank, neighbor_idx in enumerate(neighbors)\n",
    "            ],\n",
    "        }\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "def results_to_dataframe(results):\n",
    "    data = []\n",
    "    for result in results:\n",
    "        query_idx = result['query_idx']\n",
    "        for neighbor in result['neighbors']:\n",
    "            data.append({\n",
    "                \"query_idx\": query_idx,\n",
    "                \"tweet_id\": neighbor[\"tweet_id\"],\n",
    "                \"emotion\": neighbor[\"emotions\"],\n",
    "                \"distance\": neighbor[\"distance\"]\n",
    "            })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "results = search_faiss(query_embeddings, top_k=7)\n",
    "results_df = results_to_dataframe(results)\n",
    "\n",
    "###Part 4: Vote the simular embedding's emotions to get the results ###\n",
    "\n",
    "\n",
    "def perform_voting(results_df):\n",
    "    voting_results = results_df.groupby('query_idx')['emotion'].apply(\n",
    "        lambda x: x.value_counts().idxmax()  \n",
    "    ).reset_index()\n",
    "    voting_results.columns = ['query_idx', 'voted_emotion']  \n",
    "    return voting_results\n",
    "\n",
    "query_embeddings = get_batch_embeddings(emotionmerged_df_test['text'].to_list())  \n",
    "results = search_faiss(query_embeddings, top_k=7)\n",
    "\n",
    "results_df = results_to_dataframe(results)\n",
    "voting_df = perform_voting(results_df)\n",
    "\n",
    "y_test_pred=voting_df['voted_emotion'].values\n",
    "submission = pd.DataFrame({\n",
    "    'id': emotionmerged_df_test['tweet_id'],\n",
    "    'emotion': y_pred_labels\n",
    "})\n",
    "\n",
    "\n",
    "# I was too late to finish the Kaggle competition.\n",
    "# I used a random sample of 1,000 records from the training set to generate the results.\n",
    "\n",
    "# Accuracy: 0.5220\n",
    "# Precision: 0.5139\n",
    "# Recall: 0.5220\n",
    "# F1 Score: 0.4985\n",
    "\n",
    "# Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#        anger       0.60      0.27      0.37        22\n",
    "# anticipation       0.53      0.46      0.49       160\n",
    "#      disgust       0.35      0.26      0.30        92\n",
    "#         fear       0.40      0.21      0.28        47\n",
    "#          joy       0.55      0.81      0.66       364\n",
    "#      sadness       0.46      0.40      0.43       139\n",
    "#     surprise       0.50      0.17      0.26        23\n",
    "#        trust       0.58      0.35      0.43       153\n",
    "\n",
    "#     accuracy                           0.52      1000\n",
    "#    macro avg       0.50      0.37      0.40      1000\n",
    "# weighted avg       0.51      0.52      0.50      1000\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
